{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f7gAmU-HPTQ"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxnp8wVrHbIu"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWkttFn4I43d"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade accelerate\n",
        "!pip uninstall -y transformers accelerate\n",
        "!pip install transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chP18nXUJNPQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO7yOomCKlFi"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM,AutoTokenizer\n",
        "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sru9kOyyLezi"
      },
      "outputs": [],
      "source": [
        "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwvQtGb6Lmpr"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset_samsum=load_dataset(\"knkarthick/samsum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKg9EX1pNVLa"
      },
      "outputs": [],
      "source": [
        "dataset_samsum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4le7ucyN6bA"
      },
      "outputs": [],
      "source": [
        "dataset_samsum[\"train\"][0][\"dialogue\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8J6LVkeORy2"
      },
      "outputs": [],
      "source": [
        "dataset_samsum[\"train\"][0][\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRuSe6TfOYkx"
      },
      "outputs": [],
      "source": [
        "split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n",
        "print(f\"split_lengths: {split_lengths}\")\n",
        "print(f\"Features: {dataset_samsum['train'].column_names}\\n\")\n",
        "print(f\"dialogue: {dataset_samsum[\"train\"][0][\"dialogue\"]}\\n\")\n",
        "print(f\"summarization: {dataset_samsum[\"train\"][0][\"summary\"]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCoP2nVnTG0h"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(example_batch):\n",
        "  input_encodings=tokenizer(example_batch['dialogue'],max_length=1024,truncation=True)\n",
        "\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    target_encodings=tokenizer(example_batch['summary'],max_length=128,truncation=True)\n",
        "\n",
        "  return {\n",
        "      \"input_ids\":input_encodings[\"input_ids\"],\n",
        "      \"attention_mask\":input_encodings[\"attention_mask\"],\n",
        "      \"labels\":target_encodings[\"input_ids\"]\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfC0rwzBXETm"
      },
      "outputs": [],
      "source": [
        "dataset_samsum_pt=dataset_samsum.map(convert_examples_to_features,batched = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQkVRtr_YSfF"
      },
      "outputs": [],
      "source": [
        "dataset_samsum_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdMSDre0Yfwm"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "seq2seq_data_collator=DataCollatorForSeq2Seq(tokenizer,model=model_pegasus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRHxCMRgYxG0"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments,Trainer\n",
        "\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir=\"pegasus-samsum\",\n",
        "    num_train_epochs=3,\n",
        "    warmup_steps=50,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    gradient_accumulation_steps=1,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAwIK5I8ZNBf"
      },
      "outputs": [],
      "source": [
        "trainer=Trainer(model=model_pegasus,args=trainer_args,\n",
        "                tokenizer=tokenizer,data_collator=seq2seq_data_collator,\n",
        "                train_dataset=dataset_samsum_pt['test'],\n",
        "                eval_dataset=dataset_samsum_pt['validation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HJMFZtZTZs0j"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weGDqCS5Z_ej"
      },
      "outputs": [],
      "source": [
        "model_pegasus.save_pretrained(\"pegasus-samsum-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm8wA20oHRvP"
      },
      "outputs": [],
      "source": [
        "tokenizer.save_pretrained(\"tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "gen_kwargs = {\"length_penalty\":0.8,\"num_beams\":8,\"max_length\":150}\n",
        "\n",
        "pipe=pipeline(\"summarization\",model=\"pegasus-samsum-model\",tokenizer=tokenizer)\n",
        "\n",
        "print(\"input\")\n",
        "sample_text=\"\"\"Alex: Hey, did you guys finish the presentation slides for tomorrow’s client meeting?\n",
        "\n",
        "Priya: Almost! I just need to add the market analysis section and update the charts with last week’s data.\n",
        "\n",
        "Rahul: I updated the charts yesterday, Priya. Check the shared folder — file name is Market_Trends_v3.\n",
        "\n",
        "Priya: Oh great, thanks Rahul! I was about to redo them. That saves me a lot of time.\n",
        "\n",
        "Alex: Perfect. I’ll handle the opening and closing remarks, but someone needs to finalize the Q&A section.\n",
        "\n",
        "Priya: I can do that once I review the latest client feedback.\n",
        "\n",
        "Rahul: By the way, did we decide on the software demo flow? The last time, it froze midway.\n",
        "\n",
        "Alex: Right, I spoke with the tech team. They optimized the backend, and the new build should be stable.\n",
        "\n",
        "Priya: That’s good news. Should we run one quick test after lunch?\n",
        "\n",
        "Rahul: Works for me. Around 2 PM?\n",
        "\n",
        "Alex: Yep, 2 PM it is. Let’s meet in the conference room — we’ll do a dry run of the entire presentation.\n",
        "\n",
        "Priya: Cool. I’ll bring printouts just in case the projector glitches again.\n",
        "\n",
        "Rahul: Smart move! Let’s hope everything goes smoothly this time.\"\"\"\n",
        "print(sample_text)\n",
        "\n",
        "print(\"\\n model summary :\\n\")\n",
        "print(pipe(sample_text,**gen_kwargs)[0][\"summary_text\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "9AgL5DO2MPsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(sample_text,**gen_kwargs)"
      ],
      "metadata": {
        "id": "LC4Ez8MaNNf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B4VVqkI0NlEO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}